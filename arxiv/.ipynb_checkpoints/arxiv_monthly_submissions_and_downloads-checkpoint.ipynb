{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arXiv Monthly Submissions & Downloads\n",
    "\n",
    "### Caveats\n",
    "Here are some caveats to consider, taken from the [arXiv website](https://arxiv.org).\n",
    "> _While we have attempted to extract download data representing unique full-text downloads by real users, there are many factors which affect accuracy. These factors include:_\n",
    "    >>1. _the data is from the main [arXiv site](https://arxiv.org) and the arXiv mirrors, though some mirror data is incomplete;_\n",
    "    >>2. _only web downloads are included (and not FTP or email \"downloads\" that were formerly supported);_\n",
    "    >>3. _we have counted downloads according to the COUNTER algorithm which excludes rapid repeat downloads;_\n",
    "    >>4. _we have attempted to identify and remove robot or automated downloads from the count (false positives lead to undercounting, failing to identify robots leads to overcounting);_\n",
    "    >>5. _data prior to 2009 has not been cleaned with as much care as later data, it shows trends nonetheless._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# The usual suspects ...\n",
    "import time_series as ts\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels\n",
    "\n",
    "# And their accomplices ...\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "# Plotting settings\n",
    "sns.set(context='notebook', style='whitegrid', palette='deep', rc=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the data\n",
    "downloads = pd.read_csv(\n",
    "    'get_monthly_downloads_extracted_05-04-2018.csv')\n",
    "submissions = pd.read_csv(\n",
    "    'get_monthly_submissions_extracted-05-04-2018.csv')\n",
    "data = pd.merge(submissions, downloads, on='month')\n",
    "\n",
    "# Create a new file with the combined data\n",
    "data.to_csv(\n",
    "    'combined_submissions_and_downloads.csv', \n",
    "    sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 rows\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Columns | Description | Data Type | Action |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| `month` | month of activity | `string` | change to `datetime` |\n",
    "| `submissions` | number of submissions made on a particular month | `integer` | do nothing |\n",
    "| `historical_delta` | _undefined_ | `integer` | do nothing |\n",
    "| `downloads` | number of downloads made on a particular month | `integer` | do nothing |\n",
    " \n",
    "Our dataset has 4 columns and 290 rows. There are no missing values. We'll now proceed with further cleaning of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing month to 'datetime'\n",
    "ts.convert_to_datetime(data=data, column='month')\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully changed the `month` into a _datetime_ object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Number of submissions and downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of submissions vs. number of downloads\n",
    "filterwarnings('ignore')\n",
    "sns.jointplot(data=data, x='submissions', y='downloads', color='blue', kind='reg', size=13, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the number of submissions against downloads, we find a strong linear correlation of $.91$ between the two variables. This tells us that as the number of submissions increases, so does the number of downloads.\n",
    "\n",
    "From the scatterplot, we also find that submissions are more densely distributed in the range of $1 - 8000$. While on the other hand, downloads are more densely distributed in the range of $0 - 7.5$ million.\n",
    "\n",
    "***\n",
    "\n",
    "### Historical Delta ($h_\\delta$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the time series\n",
    "historical_delta = ts.create_series(data=data, time_column='month', category_column='historical_delta')\n",
    "\n",
    "# Historical delta over time\n",
    "ts.plot_series(historical_delta, title='Historical Delta ($h_{\\delta}$) Over Time', ylabel='Historical Delta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stationarity of Historical Delta ($h_{\\delta}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.test_stationarity(historical_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "**insert summary here**\n",
    "\n",
    "The _historical delta_ does not seem to show and trend or seasonality overtime. There are severe flactuations in the earlier years between $1994 - 2003$. After this period, the values are flatter along $0$.\n",
    "\n",
    "Results from the Dickey-Fuller test show a test statistic value of $-2.27$, which is close to the critical values, further justifying a lack of trend.\n",
    "\n",
    "***\n",
    "\n",
    "### Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the submissions time series\n",
    "submissions = ts.create_series(data=data, time_column='month', category_column='submissions')\n",
    "\n",
    "# Number of submissions over time\n",
    "ts.plot_series(submissions, title='Number of Submissions Over Times', ylabel='Submissions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There has been a general upward trend in the number of submissions from $1994 - 2017$. There are relatively fewer flactuations in the period between $1994 - 2002$ compared to the period between $2003$ to the present date.\n",
    "\n",
    "#### Stationarity of Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.test_stationarity(submissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly have a rising trend over time. _This is not a stationary time series_. This can be observed from the rising mean, even though the standard deviation remains low.\n",
    "\n",
    "We will now try to reducing the trend using logarithms. The intention is to penalize higher values more than lower values resulting in a flatter or less steeep trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing the trend by applying logarithms\n",
    "submissions_log = np.log(submissions)\n",
    "\n",
    "# Testing for stationarity\n",
    "ts.test_stationarity(submissions_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logarithms have tried to remove some of the steep trend and has also made the standard much more flat. However, closer inspection shows that we still have a rising trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Removing the rolling mean\n",
    "submissions_log_diff = submissions_log - submissions_log.rolling(window=12, center=False).mean().dropna()\n",
    "submissions_log_diff.dropna(inplace=True)\n",
    "ts.test_stationarity(submissions_log_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Exponentially weighted moving average\n",
    "ewa = submissions_log.ewm(halflife=12).mean()\n",
    "ts.plot_series(data=submissions_log, \n",
    "               data2=ewa, \n",
    "               color='blue', \n",
    "               title='Exponentially Weighted Moving Average', \n",
    "               ylabel='Submissions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the exponentially weighted mean from the series\n",
    "submissions_log_ewa = submissions_log - ewa\n",
    "submissions_log_ewa.dropna(inplace=True)\n",
    "ts.test_stationarity(submissions_log_ewa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differencing\n",
    "submissions_log_diff_shift = submissions_log - submissions_log.shift()\n",
    "ts.plot_series(submissions_log_diff_shift, title='Differencing', ylabel='Submissions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_log_diff_shift.dropna(inplace=True)\n",
    "ts.test_stationarity(submissions_log_diff_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposing\n",
    "decomposition = seasonal_decompose(submissions_log)\n",
    "\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(22, 12))\n",
    "# Original\n",
    "plt.subplot(411)\n",
    "plt.plot(submissions_log, color='blue')\n",
    "plt.title('Original', fontsize=18)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "# Trend\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, color='blue')\n",
    "plt.title('Trend', fontsize=18)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "# Seasonal\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal, color='blue')\n",
    "plt.title('Seasonal', fontsize=18)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "# Residual\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, color='blue')\n",
    "plt.title('Residual', fontsize=18)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking stationarity of residuals\n",
    "submissions_log_decompose_res = residual\n",
    "submissions_log_decompose_res.dropna(inplace=True)\n",
    "ts.test_stationarity(submissions_log_decompose_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting\n",
    "# ACF and PACF plots:\n",
    "lag_acf = acf(submissions_log_diff_shift, nlags=20)\n",
    "lag_pacf = pacf(submissions_log_diff_shift, nlags=20, method='ols')\n",
    "\n",
    "# Plotting ACF\n",
    "plt.figure(figsize=(22, 10))\n",
    "plt.subplot(121)\n",
    "plt.plot(lag_acf, color='blue')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.axhline(y=0, linestyle='--', color='gray')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(submissions_log)), linestyle='--', color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(submissions_log)), linestyle='--', color='gray')\n",
    "plt.title('Autocorrelation Function', fontsize=24)\n",
    "\n",
    "# Plotting PACF\n",
    "plt.subplot(122)\n",
    "plt.plot(lag_pacf, color='blue')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.axhline(y=0, linestyle='--', color='gray')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(submissions_log)), linestyle='--', color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(submissions_log)), linestyle='--', color='gray')\n",
    "plt.title('Partial Autocorrelation Function', fontsize=24)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AR Model\n",
    "filterwarnings('ignore')\n",
    "model = ARIMA(submissions_log_diff_shift, order=(1, 2, 0))\n",
    "results_AR = model.fit(disp=-1)\n",
    "\n",
    "# Plotting\n",
    "ts.plot_series(data=submissions_log_diff_shift, \n",
    "               data2=results_AR.fittedvalues,\n",
    "               ylabel='Submissions', \n",
    "               title='RSS: {}'.format(sum((results_AR.fittedvalues - submissions_log_diff_shift).fillna(0))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_AR.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MA Model\n",
    "filterwarnings('ignore')\n",
    "model = ARIMA(submissions_log, order=(0, 1, 2))\n",
    "results_MA = model.fit(disp=-1)\n",
    "\n",
    "# Plotting\n",
    "ts.plot_series(data=submissions_log_diff_shift, \n",
    "               data2=results_MA.fittedvalues,\n",
    "               ylabel='Submissions', \n",
    "               title='RSS: {}'.format(sum((results_MA.fittedvalues - submissions_log_diff_shift).fillna(0))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_MA.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA Model\n",
    "filterwarnings('ignore')\n",
    "model = ARIMA(submissions_log, order=(1, 1, 2))\n",
    "results_ARIMA = model.fit(disp=-1)\n",
    "\n",
    "# Plotting\n",
    "ts.plot_series(data=submissions_log_diff_shift, \n",
    "               data2=results_ARIMA.fittedvalues,\n",
    "               ylabel='Submissions', \n",
    "               title='RSS: {}'.format(sum((results_ARIMA.fittedvalues - submissions_log_diff_shift).fillna(0))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_ARIMA.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reversing to the original scale\n",
    "predictions_MA_diff = pd.Series(results_MA.fittedvalues, copy=True)\n",
    "\n",
    "# Cumulative sum\n",
    "predictions_MA_diff_cumsum = predictions_MA_diff.cumsum()\n",
    "\n",
    "# Adding the base number\n",
    "predictions_MA_log = pd.Series(submissions_log.ix[0], index=submissions_log.index)\n",
    "predictions_MA_log = predictions_MA_log.add(predictions_MA_diff_cumsum, fill_value=0)\n",
    "\n",
    "# Taking the exponent\n",
    "predictions_MA = np.exp(predictions_MA_log)\n",
    "\n",
    "# Plotting\n",
    "ts.plot_predictions(data=submissions, \n",
    "                    data2=predictions_MA, \n",
    "                    ylabel='Submissions', \n",
    "                    title='RMSE {}'.format(np.sqrt(sum((predictions_MA - submissions)**2)/len(submissions))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "**insert summary here**\n",
    "\n",
    "***\n",
    "\n",
    "### Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the time series\n",
    "downloads = ts.create_series(data=data, time_column='month', category_column='downloads')\n",
    "\n",
    "# Number of downloads over time\n",
    "ts.plot_series(downloads, title='Number of Downloads Over Time', ylabel='Downloads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over time, downloads show a rising trend from $1995$ and gained a lot of momentum in $2012$. The years after $2012$ show significant increases, however there is a decrease in $2016$. After the drop in $2016$, the number of downloads rises even higher reaching a peak of close to 2 million downloads towards the end of $2017$.\n",
    "\n",
    "#### Stationarity of Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.test_stationarity(downloads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dickey-Fuller test shows a high test statistic relative to the sub-zero critical values. This means the number of downloads have a rolling mean that rises over time even though the standard deviation remains relatively low.\n",
    "\n",
    "We also try to remove the trend in the downloads data by apply logarithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Removing seasonality and trend\n",
    "downloads_log = np.log(downloads)\n",
    "downloads_log = downloads_log.replace(np.negative(np.inf), 0)\n",
    "downloads_log.dropna(inplace=True)\n",
    "ts.test_stationarity(downloads_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Removing the rolling mean\n",
    "downloads_log_diff = downloads_log - downloads_log.rolling(window=12, center=False).mean().dropna()\n",
    "downloads_log_diff.dropna(inplace=True)\n",
    "ts.test_stationarity(downloads_log_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Exponentially weighted moving average\n",
    "ewa = downloads_log.ewm(halflife=12).mean()\n",
    "\n",
    "# Plotting\n",
    "ts.plot_series(data=downloads_log, \n",
    "               data2=ewa, \n",
    "               color='blue', \n",
    "               title='Exponentially Weighted Moving Average', \n",
    "               ylabel='Downloads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the exponentially weighted mean from the series\n",
    "downloads_log_ewa = downloads_log - ewa\n",
    "downloads_log_ewa.dropna(inplace=True)\n",
    "ts.test_stationarity(downloads_log_ewa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differencing\n",
    "downloads_log_diff_shift = downloads_log - downloads_log.shift()\n",
    "ts.plot_series(downloads_log_diff_shift, title='Differencing', ylabel='Downloads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloads_log_diff_shift.dropna(inplace=True)\n",
    "ts.test_stationarity(downloads_log_diff_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomposing\n",
    "decomposition = seasonal_decompose(downloads_log)\n",
    "\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(22, 12))\n",
    "# Original\n",
    "plt.subplot(411)\n",
    "plt.plot(downloads_log, color='blue')\n",
    "plt.title('Original', fontsize=18)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "# Trend\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, color='blue')\n",
    "plt.title('Trend', fontsize=18)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "# Seasonal\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal, color='blue')\n",
    "plt.title('Seasonal', fontsize=18)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "# Residual\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, color='blue')\n",
    "plt.title('Residual', fontsize=18)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking stationarity of residuals\n",
    "downloads_log_decompose_res = residual\n",
    "downloads_log_decompose_res.dropna(inplace=True)\n",
    "ts.test_stationarity(downloads_log_decompose_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting\n",
    "# ACF and PACF plots:\n",
    "lag_acf = acf(downloads_log_diff_shift, nlags=20)\n",
    "lag_pacf = pacf(downloads_log_diff_shift, nlags=20, method='ols')\n",
    "\n",
    "# Plotting ACF\n",
    "plt.figure(figsize=(22, 10))\n",
    "plt.subplot(121)\n",
    "plt.plot(lag_acf, color='blue')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.axhline(y=0, linestyle='--', color='gray')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(downloads_log)), linestyle='--', color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(downloads_log)), linestyle='--', color='gray')\n",
    "plt.title('Autocorrelation Function', fontsize=24)\n",
    "\n",
    "# Plotting PACF\n",
    "plt.subplot(122)\n",
    "plt.plot(lag_pacf, color='blue')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.axhline(y=0, linestyle='--', color='gray')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(downloads_log)), linestyle='--', color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(downloads_log)), linestyle='--', color='gray')\n",
    "plt.title('Partial Autocorrelation Function', fontsize=24)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AR Model\n",
    "filterwarnings('ignore')\n",
    "model = ARIMA(downloads_log_diff_shift, order=(1, 1, 0))\n",
    "results_AR = model.fit(disp=-1)\n",
    "\n",
    "# Plotting\n",
    "ts.plot_series(data=downloads_log_diff_shift, \n",
    "               data2=results_AR.fittedvalues,\n",
    "               ylabel='Downloads', \n",
    "               title='RSS: {}'.format(sum((results_AR.fittedvalues - downloads_log_diff_shift).fillna(0))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_AR.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MA Model\n",
    "filterwarnings('ignore')\n",
    "model = ARIMA(downloads_log, order=(0, 1, 1))\n",
    "results_MA = model.fit(disp=-1)\n",
    "\n",
    "# Plotting\n",
    "ts.plot_series(data=downloads_log_diff_shift, \n",
    "               data2=results_MA.fittedvalues,\n",
    "               ylabel='Downloads', \n",
    "               title='RSS: {}'.format(sum((results_MA.fittedvalues - downloads_log_diff_shift).fillna(0))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_MA.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA Model\n",
    "filterwarnings('ignore')\n",
    "model = ARIMA(downloads_log, order=(1, 1, 1))\n",
    "results_ARIMA = model.fit(disp=-1)\n",
    "\n",
    "# Plotting\n",
    "ts.plot_series(data=downloads_log_diff_shift, \n",
    "               data2=results_ARIMA.fittedvalues,\n",
    "               ylabel='Downloads',\n",
    "               title='RSS: {}'.format(sum((results_ARIMA.fittedvalues - downloads_log_diff_shift).fillna(0))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_ARIMA.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By MA\n",
    "# Reversing to the original scale\n",
    "predictions_MA_diff = pd.Series(results_MA.fittedvalues, copy=True)\n",
    "\n",
    "# Cumulative sum\n",
    "predictions_MA_diff_cumsum = predictions_MA_diff.cumsum()\n",
    "\n",
    "# Adding the base number\n",
    "predictions_MA_log = pd.Series(downloads_log.ix[0], index=downloads_log.index)\n",
    "predictions_MA_log = predictions_MA_log.add(predictions_MA_diff_cumsum, fill_value=0)\n",
    "\n",
    "# Taking the exponent\n",
    "predictions_MA = np.exp(predictions_MA_log)\n",
    "\n",
    "# Plotting\n",
    "ts.plot_predictions(data=downloads, \n",
    "                    data2=predictions_MA, \n",
    "                    ylabel='Downloads', \n",
    "                    title='RMSE {}'.format(np.sqrt(sum((predictions_MA - downloads)**2)/len(downloads))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "**insert summary here**\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
